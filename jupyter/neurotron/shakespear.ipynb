{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "266b3024-9eb1-43e0-9f33-2c06e959a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny shakespear\n",
    "\n",
    "from neurotron import Cells, Train, Token, Monitor, Ansi, SynapseErr\n",
    "import neurotron.math as nm\n",
    "isa = isinstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69027699-a8a9-458e-9589-4fdb83a32b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(Train):\n",
    "    def __init__(self,cells,plot=False):\n",
    "        super().__init__(cells)\n",
    "        self.plotting = plot\n",
    "\n",
    "    def prediction(self,context):\n",
    "        if context in self._contexts:\n",
    "            info = self._contexts[context]\n",
    "            counters = []; total = 0\n",
    "            for key in info:\n",
    "                if not key in ['#','@']:\n",
    "                    n,refer,idx = info[key]\n",
    "                    total += n\n",
    "                    counters.append(n)\n",
    "                    #print('    statistics: %s:' % key,(counters,total))\n",
    "            result = []; k = 0\n",
    "            src = self.address(context)\n",
    "            for key in info:\n",
    "                if not key in ['#','@']:\n",
    "                    ratio = counters[k]/total\n",
    "                    k += 1\n",
    "                    n,refer,idx = info[key]\n",
    "                    dst = self.address(refer)\n",
    "                    result.append((refer,ratio,src,dst))\n",
    "                    #print('    predict(%g%%): %s ->'%(100*ratio,key),info[key])\n",
    "            return result\n",
    "\n",
    "    def predict(self,context):\n",
    "        results = self.prediction(context)\n",
    "        for prediction in results:\n",
    "            refer,ratio,src,dst = prediction\n",
    "            print('    %g%%: ->' % (100*ratio),refer,src,dst)\n",
    "    \n",
    "    def address(self,context):\n",
    "        if context in self._contexts:\n",
    "            info = self._contexts[context]\n",
    "            #print('##### info:',info)\n",
    "            m,n,d,s = self.cells.shape\n",
    "            idx = train.code((info['@'][1])).list()[0]; \n",
    "            jdx = info['#'][0]\n",
    "            assert len(idx) == len(jdx)\n",
    "            kdx = [jdx[s]*m+idx[s] for s in range(len(idx))]\n",
    "            #return ((m,n),idx,jdx,kdx)\n",
    "            return kdx\n",
    "        return None\n",
    "\n",
    "    def learn(self,context):\n",
    "        results = self.prediction(context)\n",
    "        for prediction in results:\n",
    "            refer,ratio,src,dst = prediction\n",
    "            print('    %g%%: ->' % (100*ratio),refer,src,dst)\n",
    "            self.cells.init()\n",
    "            for k in dst:\n",
    "                self.cells.X[k] = 1\n",
    "            for k in src:\n",
    "                self.cells.Y[k] = 1\n",
    "\n",
    "            self.cells.connect(src,dst)\n",
    "            title = 'learn: ' + refer\n",
    "            if self.plotting: self.plot(title)\n",
    "            self.cells.init()\n",
    "\n",
    "    def program(self,verbose=0):   # learn all contexts\n",
    "        \"\"\"\n",
    "        learn all contexts\n",
    "        >>> train = Trainer(Cells('Mary'))\n",
    "        >>> train.program()\n",
    "        \"\"\"\n",
    "        for context in self._contexts:\n",
    "            results = self.prediction(context)\n",
    "            for prediction in results:\n",
    "                refer,ratio,src,dst = prediction\n",
    "                #print('    %g%%: ->' % (100*ratio),refer,src,dst)\n",
    "                for k in dst:\n",
    "                    self.cells.X[k] = 1\n",
    "                for k in src:\n",
    "                    self.cells.Y[k] = 1\n",
    "                try:\n",
    "                    self.cells.connect(src,dst)\n",
    "                    if verbose:\n",
    "                        print(Ansi.G + '    learning:',context,'OK'+Ansi.N)\n",
    "                except SynapseErr:\n",
    "                    print(Ansi.R+'    learning:',context,'FAIL'+Ansi.N)\n",
    "\n",
    "    def plot(self,title=''):\n",
    "        m,n,d,s = self.cells.shape\n",
    "        mon = Monitor(m,n)\n",
    "        self.cells.plot(mon,label=True)\n",
    "        mon.title(title)\n",
    "\n",
    "    def analyse(self,sentence,all=False):\n",
    "        if all:\n",
    "            prediction = self.cells.process(sentence)\n",
    "        else:\n",
    "            prediction = self.cells.run(sentence)\n",
    "            self.plot()\n",
    "        return prediction\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3890b85c-52b6-4d2e-b660-9eaea77266d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \\\n",
    "\"\"\"\n",
    "First Citizen:\n",
    "We are accounted poor citizens, the patricians good.\n",
    "What authority surfeits on would relieve us: if they\n",
    "would yield us but the superfluity, while it were\n",
    "wholesome, we might guess they relieved us humanely;\n",
    "but they think we are too dear: the leanness that\n",
    "afflicts us, the object of our misery, is as an\n",
    "inventory to particularise their abundance; our\n",
    "sufferance is a gain to them Let us revenge this with\n",
    "our pikes, ere we become rakes: for the gods know I\n",
    "speak this in hunger for bread, not in thirst for revenge.\n",
    "\"\"\"\n",
    "def chunkify(text,m,n): \n",
    "    k = 1; chunks = []\n",
    "    for i in range(m): \n",
    "        row = [] \n",
    "        for j in range(n):\n",
    "            row.append(text[k]); k += 1\n",
    "            chunks.append(row);\n",
    "        return chunks\n",
    "\n",
    "chunks = chunkify(text,10,8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b98a850-1033-47b7-b8da-71dfcdf7b71d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m train \u001b[38;5;241m=\u001b[39m Trainer(cells,plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#train.analyse('Lisa likes to paint',all=True)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#train.predict('<Lisa likes to>')\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#train.program()\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#train.analyse('Lisa likes to paint',all=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/Bluenetics/Git/Neural/neurotron-develop/neurotron/src/neurotron/cluster/trainer.py:215\u001b[0m, in \u001b[0;36mTrain.__call__\u001b[0;34m(self, context, arg)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     arg \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m();  context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isa(arg,\u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    217\u001b[0m     sequence \u001b[38;5;241m=\u001b[39m arg  \u001b[38;5;66;03m# rename\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "cells = Cells((2,9,10,3),Toy('Mary').token,verbose=0)\n",
    "train = Trainer(cells,plot=True)\n",
    "\n",
    "for chunk in chunks:\n",
    "    train(chunk)\n",
    "    break\n",
    "\n",
    "#train.analyse('Lisa likes to paint',all=True)\n",
    "#train.predict('<Lisa likes to>')\n",
    "#train.program()\n",
    "\n",
    "#train.analyse('Lisa likes to paint',all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6c10674-a57f-450b-bc7a-2a2fae57577f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m cells \u001b[38;5;241m=\u001b[39m Cells((\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m3\u001b[39m),token,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m train \u001b[38;5;241m=\u001b[39m Trainer(cells,plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#train('Lisa likes to dance .',8)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#train('Mary likes to sing .',5)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#train.analyse('Lisa likes to paint',all=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/Bluenetics/Git/Neural/neurotron-develop/neurotron/src/neurotron/cluster/trainer.py:215\u001b[0m, in \u001b[0;36mTrain.__call__\u001b[0;34m(self, context, arg)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     arg \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m();  context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isa(arg,\u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    217\u001b[0m     sequence \u001b[38;5;241m=\u001b[39m arg  \u001b[38;5;66;03m# rename\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "token = Token({'.':[1,1,1,0,0,0,0,0,0]})\n",
    "cells = Cells((3,9,10,3),token,verbose=0)\n",
    "train = Trainer(cells,plot=True)\n",
    "train(chunk)\n",
    "#train('Lisa likes to dance .',8)\n",
    "#train('Mary likes to sing .',5)\n",
    "\n",
    "#train.predict('<Lisa likes to>')\n",
    "#train.program()\n",
    "\n",
    "#train.analyse('Lisa likes to paint',all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5beb05-b3d9-496a-86a8-5a5fb7fa44ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45dd8a61-4a94-464e-8a5f-6a6240a21e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neurotron.cluster.token.Token"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5011fff-5bb6-45bc-9b15-1a9ca81d2e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
